{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regresi√≥n Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.svm import SVC, SVR, LinearSVR\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Wine_reviews_climate_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70030 entries, 0 to 70029\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      70030 non-null  int64  \n",
      " 1   country         70030 non-null  object \n",
      " 2   description     70030 non-null  object \n",
      " 3   points          70030 non-null  int64  \n",
      " 4   price           70030 non-null  float64\n",
      " 5   taster_name     70030 non-null  object \n",
      " 6   variety         70030 non-null  object \n",
      " 7   winery          70030 non-null  object \n",
      " 8   Year            70030 non-null  int64  \n",
      " 9   region          70030 non-null  object \n",
      " 10  Latitude        70030 non-null  float64\n",
      " 11  Longitude       70030 non-null  float64\n",
      " 12  Lat_x           70030 non-null  float64\n",
      " 13  Long_x          70030 non-null  float64\n",
      " 14  temp_anual      70030 non-null  float64\n",
      " 15  temp_max_anual  70030 non-null  float64\n",
      " 16  temp_min_anual  70030 non-null  float64\n",
      " 17  pre_anual       70030 non-null  float64\n",
      " 18  etp_anual       70030 non-null  int64  \n",
      "dtypes: float64(9), int64(4), object(6)\n",
      "memory usage: 10.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "country           0\n",
       "description       0\n",
       "points            0\n",
       "price             0\n",
       "taster_name       0\n",
       "variety           0\n",
       "winery            0\n",
       "Year              0\n",
       "region            0\n",
       "Latitude          0\n",
       "Longitude         0\n",
       "Lat_x             0\n",
       "Long_x            0\n",
       "temp_anual        0\n",
       "temp_max_anual    0\n",
       "temp_min_anual    0\n",
       "pre_anual         0\n",
       "etp_anual         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "country           0\n",
       "description       0\n",
       "points            0\n",
       "price             0\n",
       "taster_name       0\n",
       "variety           0\n",
       "winery            0\n",
       "Year              0\n",
       "region            0\n",
       "Latitude          0\n",
       "Longitude         0\n",
       "Lat_x             0\n",
       "Long_x            0\n",
       "temp_anual        0\n",
       "temp_max_anual    0\n",
       "temp_min_anual    0\n",
       "pre_anual         0\n",
       "etp_anual         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deleteing rows with price = 0\n",
    "df.dropna(subset = ['price'], inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lat_x</th>\n",
       "      <th>Long_x</th>\n",
       "      <th>temp_anual</th>\n",
       "      <th>temp_max_anual</th>\n",
       "      <th>temp_min_anual</th>\n",
       "      <th>pre_anual</th>\n",
       "      <th>etp_anual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2011</td>\n",
       "      <td>41.75</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>13.01</td>\n",
       "      <td>19.44</td>\n",
       "      <td>6.61</td>\n",
       "      <td>388.5</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2011</td>\n",
       "      <td>41.75</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>13.01</td>\n",
       "      <td>19.44</td>\n",
       "      <td>6.61</td>\n",
       "      <td>388.5</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>87</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2011</td>\n",
       "      <td>41.75</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>13.01</td>\n",
       "      <td>19.44</td>\n",
       "      <td>6.61</td>\n",
       "      <td>388.5</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>91</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2011</td>\n",
       "      <td>41.75</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>13.01</td>\n",
       "      <td>19.44</td>\n",
       "      <td>6.61</td>\n",
       "      <td>388.5</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>87</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2011</td>\n",
       "      <td>41.75</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>13.01</td>\n",
       "      <td>19.44</td>\n",
       "      <td>6.61</td>\n",
       "      <td>388.5</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70025</th>\n",
       "      <td>USA</td>\n",
       "      <td>84</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Matt Kettmann</td>\n",
       "      <td>2012</td>\n",
       "      <td>34.75</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>13.96</td>\n",
       "      <td>20.23</td>\n",
       "      <td>7.75</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70026</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>90</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Jeff Jenssen</td>\n",
       "      <td>2012</td>\n",
       "      <td>46.75</td>\n",
       "      <td>6.75</td>\n",
       "      <td>9.15</td>\n",
       "      <td>13.46</td>\n",
       "      <td>4.87</td>\n",
       "      <td>1382.5</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70027</th>\n",
       "      <td>France</td>\n",
       "      <td>89</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2012</td>\n",
       "      <td>45.25</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5.61</td>\n",
       "      <td>9.20</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1386.2</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70028</th>\n",
       "      <td>France</td>\n",
       "      <td>89</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2012</td>\n",
       "      <td>45.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>10.71</td>\n",
       "      <td>15.25</td>\n",
       "      <td>6.22</td>\n",
       "      <td>976.2</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70029</th>\n",
       "      <td>Italy</td>\n",
       "      <td>87</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Kerin O‚ÄôKeefe</td>\n",
       "      <td>2012</td>\n",
       "      <td>40.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.09</td>\n",
       "      <td>18.80</td>\n",
       "      <td>11.40</td>\n",
       "      <td>269.6</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70030 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           country  points  price    taster_name  Year  Lat_x  Long_x  \\\n",
       "0         Portugal      87   15.0     Roger Voss  2011  41.75   -5.75   \n",
       "1         Portugal      87   15.0     Roger Voss  2011  41.75   -5.75   \n",
       "2         Portugal      87   17.0     Roger Voss  2011  41.75   -5.75   \n",
       "3         Portugal      91   12.0     Roger Voss  2011  41.75   -5.75   \n",
       "4         Portugal      87    8.0     Roger Voss  2011  41.75   -5.75   \n",
       "...            ...     ...    ...            ...   ...    ...     ...   \n",
       "70025          USA      84   25.0  Matt Kettmann  2012  34.75 -118.25   \n",
       "70026  Switzerland      90   21.0   Jeff Jenssen  2012  46.75    6.75   \n",
       "70027       France      89   14.0     Roger Voss  2012  45.25    6.25   \n",
       "70028       France      89   18.0     Roger Voss  2012  45.75    5.75   \n",
       "70029        Italy      87   25.0  Kerin O‚ÄôKeefe  2012  40.25   15.25   \n",
       "\n",
       "       temp_anual  temp_max_anual  temp_min_anual  pre_anual  etp_anual  \n",
       "0           13.01           19.44            6.61      388.5       1200  \n",
       "1           13.01           19.44            6.61      388.5       1200  \n",
       "2           13.01           19.44            6.61      388.5       1200  \n",
       "3           13.01           19.44            6.61      388.5       1200  \n",
       "4           13.01           19.44            6.61      388.5       1200  \n",
       "...           ...             ...             ...        ...        ...  \n",
       "70025       13.96           20.23            7.75      325.0       1176  \n",
       "70026        9.15           13.46            4.87     1382.5        696  \n",
       "70027        5.61            9.20            2.05     1386.2        714  \n",
       "70028       10.71           15.25            6.22      976.2        807  \n",
       "70029       15.09           18.80           11.40      269.6       1077  \n",
       "\n",
       "[70030 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['description', 'variety', 'winery', 'Latitude', 'Longitude', 'region', 'Unnamed: 0'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['country', 'taster_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70030 entries, 0 to 70029\n",
      "Data columns (total 70 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   points                          70030 non-null  int64  \n",
      " 1   price                           70030 non-null  float64\n",
      " 2   Year                            70030 non-null  int64  \n",
      " 3   Lat_x                           70030 non-null  float64\n",
      " 4   Long_x                          70030 non-null  float64\n",
      " 5   temp_anual                      70030 non-null  float64\n",
      " 6   temp_max_anual                  70030 non-null  float64\n",
      " 7   temp_min_anual                  70030 non-null  float64\n",
      " 8   pre_anual                       70030 non-null  float64\n",
      " 9   etp_anual                       70030 non-null  int64  \n",
      " 10  country_Argentina               70030 non-null  uint8  \n",
      " 11  country_Australia               70030 non-null  uint8  \n",
      " 12  country_Austria                 70030 non-null  uint8  \n",
      " 13  country_Bosnia and Herzegovina  70030 non-null  uint8  \n",
      " 14  country_Brazil                  70030 non-null  uint8  \n",
      " 15  country_Bulgaria                70030 non-null  uint8  \n",
      " 16  country_Canada                  70030 non-null  uint8  \n",
      " 17  country_Chile                   70030 non-null  uint8  \n",
      " 18  country_China                   70030 non-null  uint8  \n",
      " 19  country_Croatia                 70030 non-null  uint8  \n",
      " 20  country_Cyprus                  70030 non-null  uint8  \n",
      " 21  country_Czech Republic          70030 non-null  uint8  \n",
      " 22  country_England                 70030 non-null  uint8  \n",
      " 23  country_France                  70030 non-null  uint8  \n",
      " 24  country_Georgia                 70030 non-null  uint8  \n",
      " 25  country_Germany                 70030 non-null  uint8  \n",
      " 26  country_Greece                  70030 non-null  uint8  \n",
      " 27  country_Hungary                 70030 non-null  uint8  \n",
      " 28  country_India                   70030 non-null  uint8  \n",
      " 29  country_Israel                  70030 non-null  uint8  \n",
      " 30  country_Italy                   70030 non-null  uint8  \n",
      " 31  country_Lebanon                 70030 non-null  uint8  \n",
      " 32  country_Macedonia               70030 non-null  uint8  \n",
      " 33  country_Mexico                  70030 non-null  uint8  \n",
      " 34  country_Moldova                 70030 non-null  uint8  \n",
      " 35  country_Morocco                 70030 non-null  uint8  \n",
      " 36  country_New Zealand             70030 non-null  uint8  \n",
      " 37  country_Peru                    70030 non-null  uint8  \n",
      " 38  country_Portugal                70030 non-null  uint8  \n",
      " 39  country_Romania                 70030 non-null  uint8  \n",
      " 40  country_Serbia                  70030 non-null  uint8  \n",
      " 41  country_Slovakia                70030 non-null  uint8  \n",
      " 42  country_Slovenia                70030 non-null  uint8  \n",
      " 43  country_South Africa            70030 non-null  uint8  \n",
      " 44  country_Spain                   70030 non-null  uint8  \n",
      " 45  country_Switzerland             70030 non-null  uint8  \n",
      " 46  country_Turkey                  70030 non-null  uint8  \n",
      " 47  country_USA                     70030 non-null  uint8  \n",
      " 48  country_Ukraine                 70030 non-null  uint8  \n",
      " 49  country_Uruguay                 70030 non-null  uint8  \n",
      " 50  taster_name_Alexander Peartree  70030 non-null  uint8  \n",
      " 51  taster_name_Anna Lee C. Iijima  70030 non-null  uint8  \n",
      " 52  taster_name_Anne Krebiehl¬†MW    70030 non-null  uint8  \n",
      " 53  taster_name_Anonimo             70030 non-null  uint8  \n",
      " 54  taster_name_Carrie Dykes        70030 non-null  uint8  \n",
      " 55  taster_name_Christina Pickard   70030 non-null  uint8  \n",
      " 56  taster_name_Fiona Adams         70030 non-null  uint8  \n",
      " 57  taster_name_Jeff Jenssen        70030 non-null  uint8  \n",
      " 58  taster_name_Jim Gordon          70030 non-null  uint8  \n",
      " 59  taster_name_Joe Czerwinski      70030 non-null  uint8  \n",
      " 60  taster_name_Kerin O‚ÄôKeefe       70030 non-null  uint8  \n",
      " 61  taster_name_Lauren Buzzeo       70030 non-null  uint8  \n",
      " 62  taster_name_Matt Kettmann       70030 non-null  uint8  \n",
      " 63  taster_name_Michael Schachner   70030 non-null  uint8  \n",
      " 64  taster_name_Mike DeSimone       70030 non-null  uint8  \n",
      " 65  taster_name_Paul Gregutt        70030 non-null  uint8  \n",
      " 66  taster_name_Roger Voss          70030 non-null  uint8  \n",
      " 67  taster_name_Sean P. Sullivan    70030 non-null  uint8  \n",
      " 68  taster_name_Susan Kostrzewa     70030 non-null  uint8  \n",
      " 69  taster_name_Virginie Boone      70030 non-null  uint8  \n",
      "dtypes: float64(7), int64(3), uint8(60)\n",
      "memory usage: 9.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we separate our info, the X will be all the columns except the output variable, then the output variable, the test size 20% and the random state to have always the same output\n",
    "# is like X, X_test, y, y_test = train_test_split(variables_X, variable_Y, test_size, random_state)\n",
    "X, X_test, y, y_test = train_test_split(data.drop(columns='points'), data.points, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('poly',\n",
       "                                              PolynomialFeatures(include_bias=False)),\n",
       "                                             ('ridge', Ridge())]),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'poly__degree': [1, 2],\n",
       "                                        'ridge__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BF44E6F100>})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "dists = {'ridge__alpha' : uniform(loc=0, scale=200), 'poly__degree' : [1, 2]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "ridge_CV = RandomizedSearchCV(ridge_pipe, param_distributions=dists, n_iter=30, cv=5)\n",
    "#Now we train the model\n",
    "ridge_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poly__degree': 2, 'ridge__alpha': 99.32233104670432}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3825548667084677"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3787943726233015"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9608449459539445"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9834436640957853"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': [10, 11, 12, 13, 14, 15],\n",
       "                         'min_samples_leaf': [47, 48, 49, 50, 51, 52, 53]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Now we try a Tree Regressor\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "param_grid = {'max_depth' : [10, 11, 12, 13, 14, 15], 'min_samples_leaf' : [47, 48, 49, 50, 51, 52, 53]}\n",
    "\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "tree_CV = GridSearchCV(tree, param_grid=param_grid)\n",
    "#Now we train the model\n",
    "tree_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Parameters are : {'max_depth': 11, 'min_samples_leaf': 48}\n",
      "The best X,y score is:  0.4729605577155309\n",
      "The best X,y test score is:  0.43559249110262077\n",
      "The MAE X,y is:  1.8068281111728506\n",
      "The MAE test X,y is:  1.8703458380744113\n"
     ]
    }
   ],
   "source": [
    "print(\"The best Parameters are :\", tree_CV.best_params_)\n",
    "print(\"The best X,y score is: \", tree_CV.score(X, y))\n",
    "print(\"The best X,y test score is: \", tree_CV.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(tree_CV.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(tree_CV.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('ridge', Ridge())]),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'pca__n_components': [10, 20, 30, 40,\n",
       "                                                              60],\n",
       "                                        'ridge__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BF49EC5CA0>})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "dists = {'ridge__alpha' : uniform(loc=0, scale=200), 'pca__n_components' : [10, 20, 30, 40, 60]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "ridge_CV = RandomizedSearchCV(ridge_pipe, param_distributions=dists, n_iter=30, cv=5)\n",
    "#Now we train the model\n",
    "ridge_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca__n_components': 60, 'ridge__alpha': 196.71672820104513}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25488111208145026"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27601330436253724"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1528510221858674"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1635635778523583"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('ridge', Ridge())]),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'pca__n_components': [60, 62, 64, 66],\n",
       "                                        'ridge__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BF459469A0>})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "dists = {'ridge__alpha' : uniform(loc=0, scale=200), 'pca__n_components' : [60, 62, 64, 66]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "ridge_CV = RandomizedSearchCV(ridge_pipe, param_distributions=dists, n_iter=30, cv=5)\n",
    "#Now we train the model\n",
    "ridge_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca__n_components': 66, 'ridge__alpha': 6.125747369012879}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2556934780610557"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2765566920062328"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1506439757612035"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1624782942760796"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('poly',\n",
       "                                              PolynomialFeatures(include_bias=False)),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('ridge', Ridge())]),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'pca__n_components': [30, 40, 50, 60],\n",
       "                                        'poly__degree': [1, 2],\n",
       "                                        'ridge__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BF44E5AF40>})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),\n",
    "    ('pca', PCA()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "dists = {'ridge__alpha' : uniform(loc=0, scale=200), 'poly__degree': [1,2], 'pca__n_components' : [30, 40, 50, 60]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "ridge_CV = RandomizedSearchCV(ridge_pipe, param_distributions=dists, n_iter=30, cv=5)\n",
    "#Now we train the model\n",
    "ridge_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Parameters are : {'pca__n_components': 60, 'poly__degree': 1, 'ridge__alpha': 172.52565962730432}\n",
      "The best X,y score is:  0.2548817850785814\n",
      "The best X,y test score is:  0.27604559239218884\n",
      "The MAE X,y is:  2.152768892577137\n",
      "The MAE test X,y is:  2.1634719034809025\n"
     ]
    }
   ],
   "source": [
    "print(\"The best Parameters are :\", ridge_CV.best_params_)\n",
    "print(\"The best X,y score is: \", ridge_CV.score(X, y))\n",
    "print(\"The best X,y test score is: \", ridge_CV.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(ridge_CV.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(ridge_CV.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 191 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('linear', LinearRegression())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "linear_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "#dists = {'ridge__alpha' : uniform(loc=0, scale=200), 'poly__degree': [1,2], 'pca__n_components' : [30, 40, 50, 60]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "#Now we train the model\n",
    "linear_pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best X,y score is:  0.2562773006049426\n",
      "The best X,y test score is:  -1.2877764535941084e+18\n",
      "The MAE X,y is:  2.1501943618043127\n",
      "The MAE test X,y is:  30263775.16614799\n"
     ]
    }
   ],
   "source": [
    "print(\"The best X,y score is: \", linear_pipe.score(X, y))\n",
    "print(\"The best X,y test score is: \", linear_pipe.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(linear_pipe.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(linear_pipe.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm',\n",
       "                 LinearSVR(C=1000, epsilon=1, max_iter=10000,\n",
       "                           random_state=42))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', LinearSVR(C=1000, epsilon=1, max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best X,y score is:  0.03367518705837347\n",
      "The best X,y test score is:  0.14272707474426827\n",
      "The MAE X,y is:  2.2704148752770594\n",
      "The MAE test X,y is:  2.2635366707544993\n"
     ]
    }
   ],
   "source": [
    "print(\"The best X,y score is: \", svm.score(X, y))\n",
    "print(\"The best X,y test score is: \", svm.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(svm.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(svm.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm', SVR(C=1000, epsilon=0.5))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVR(kernel='rbf', C=1000, epsilon=0.5))\n",
    "])\n",
    "\n",
    "svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best X,y score is:  0.48239334737287676\n",
      "The best X,y test score is:  0.4509594337442103\n",
      "The MAE X,y is:  1.7598939589719105\n",
      "The MAE test X,y is:  1.825131240668002\n"
     ]
    }
   ],
   "source": [
    "print(\"The best X,y score is: \", svm.score(X, y))\n",
    "print(\"The best X,y test score is: \", svm.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(svm.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(svm.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 141 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()), ('gnb', GaussianNB())])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "gnb_pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('gnb', GaussianNB())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "#dists = {'gnb__alpha' : uniform(loc=0, scale=200)}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "#ridge_CV = RandomizedSearchCV(ridge_pipe, param_distributions=dists, n_iter=30, cv=5)\n",
    "#Now we train the model\n",
    "gnb_pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best X,y score is:  0.006657860916749964\n",
      "The best X,y test score is:  0.005997429672997287\n",
      "The MAE X,y is:  10.130515493359988\n",
      "The MAE test X,y is:  10.173639868627731\n"
     ]
    }
   ],
   "source": [
    "print(\"The best X,y score is: \", gnb_pipe.score(X, y))\n",
    "print(\"The best X,y test score is: \", gnb_pipe.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(gnb_pipe.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(gnb_pipe.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8h 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('svm',\n",
       "                                              SVR(C=1000, epsilon=0.5))]),\n",
       "                   n_iter=3,\n",
       "                   param_distributions={'svm__C': [1000, 3000, 5000],\n",
       "                                        'svm__epsilon': [0.001, 0.1, 1]})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "svr_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVR(C=1000, epsilon=0.5))\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "dists = {'svm__C' : [1000, 3000, 5000], 'svm__epsilon': [0.001, 0.1, 1]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "svr_CV = RandomizedSearchCV(svr_pipe, param_distributions=dists, n_iter=3, cv=5)\n",
    "#Now we train the model\n",
    "svr_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Parameters are : {'svm__epsilon': 1, 'svm__C': 1000}\n",
      "The best X,y score is:  0.48312998658187045\n",
      "The best X,y test score is:  0.45485682437869546\n",
      "The MAE X,y is:  1.7693013134400775\n",
      "The MAE test X,y is:  1.8224817093740744\n"
     ]
    }
   ],
   "source": [
    "print(\"The best Parameters are :\", svr_CV.best_params_)\n",
    "print(\"The best X,y score is: \", svr_CV.score(X, y))\n",
    "print(\"The best X,y test score is: \", svr_CV.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(svr_CV.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(svr_CV.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
